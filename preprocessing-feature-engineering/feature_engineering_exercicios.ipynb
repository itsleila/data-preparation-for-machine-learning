{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de834af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26cb909",
   "metadata": {},
   "source": [
    "## Part 1 - Normalização de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94bb8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset = load_iris()\n",
    "iris_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3904f089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target species  \n",
      "0       0  setosa  \n",
      "1       0  setosa  \n",
      "2       0  setosa  \n",
      "3       0  setosa  \n",
      "4       0  setosa  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(iris_dataset.data, columns=iris_dataset.feature_names)\n",
    "iris_df['target']  = iris_dataset.target\n",
    "iris_df['species'] = pd.Categorical.from_codes(iris_dataset.target, iris_dataset.target_names)\n",
    "\n",
    "\n",
    "print(iris_df.head())\n",
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced9927",
   "metadata": {},
   "source": [
    "#### Questão 1: Utilize a normalização StandardScaler para escalonar as features do Iris Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f53606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Antes da normalização -------\n",
      "Média: sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "Desvio padrão: sepal length (cm)    0.828066\n",
      "sepal width (cm)     0.435866\n",
      "petal length (cm)    1.765298\n",
      "petal width (cm)     0.762238\n",
      "dtype: float64\n",
      "----- Depois da normalização -------\n",
      "Média: sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "Desvio padrão: sepal length (cm)    1.00335\n",
      "sepal width (cm)     1.00335\n",
      "petal length (cm)    1.00335\n",
      "petal width (cm)     1.00335\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features = iris_df.drop(['target','species'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "\n",
    "df_scaled = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "\n",
    "print(\"----- Antes da normalização -------\")\n",
    "print(\"Média:\", features.mean())\n",
    "print(\"Desvio padrão:\", features.std())\n",
    "\n",
    "print(\"----- Depois da normalização -------\")\n",
    "print(\"Média:\", df_scaled.mean())\n",
    "print(\"Desvio padrão:\", df_scaled.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7b2be",
   "metadata": {},
   "source": [
    "#### Questão 2: Implemente manualmente uma função em Python para realizar o escalonamento padrão (StandardScaler), sem utilizar a função correspondente do sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af757ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Normalização StandardScaler -------\n",
      "Média:\n",
      " sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "Desvio padrão:\n",
      " sepal length (cm)    1.00335\n",
      "sepal width (cm)     1.00335\n",
      "petal length (cm)    1.00335\n",
      "petal width (cm)     1.00335\n",
      "dtype: float64\n",
      "\n",
      "----- Normalização Manual -------\n",
      "Média:\n",
      " sepal length (cm)   -4.736952e-16\n",
      "sepal width (cm)    -7.815970e-16\n",
      "petal length (cm)   -4.263256e-16\n",
      "petal width (cm)    -4.736952e-16\n",
      "dtype: float64\n",
      "Desvio padrão:\n",
      " sepal length (cm)    1.00335\n",
      "sepal width (cm)     1.00335\n",
      "petal length (cm)    1.00335\n",
      "petal width (cm)     1.00335\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def normalizacao_manual(df_iris):\n",
    "  df_normalizado = df_iris.copy()\n",
    "  for column in df_iris.columns:\n",
    "    media = df_iris[column].mean()\n",
    "    desvio_padrao = df_iris[column].std(ddof=0)\n",
    "    df_normalizado[column] = (df_iris[column] - media) / desvio_padrao\n",
    "  return df_normalizado\n",
    "\n",
    "features_normalizadas = normalizacao_manual(features)\n",
    "\n",
    "print(\"----- Normalização StandardScaler -------\")\n",
    "print(\"Média:\\n\", df_scaled.mean())\n",
    "print(\"Desvio padrão:\\n\", df_scaled.std()) \n",
    "print(\"\\n----- Normalização Manual -------\")\n",
    "print(\"Média:\\n\", features_normalizadas.mean())\n",
    "print(\"Desvio padrão:\\n\", features_normalizadas.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42c50d",
   "metadata": {},
   "source": [
    "#### Questão 3: Realize a regularização das features do Iris Dataset utilizando a norma Euclidiana (L2). Exiba os resultados obtidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b65bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80377277 0.55160877 0.22064351 0.0315205 ]\n",
      " [0.82813287 0.50702013 0.23660939 0.03380134]\n",
      " [0.80533308 0.54831188 0.2227517  0.03426949]\n",
      " [0.80003025 0.53915082 0.26087943 0.03478392]\n",
      " [0.790965   0.5694948  0.2214702  0.0316386 ]\n",
      " [0.78417499 0.5663486  0.2468699  0.05808704]\n",
      " [0.78010936 0.57660257 0.23742459 0.0508767 ]\n",
      " [0.80218492 0.54548574 0.24065548 0.0320874 ]\n",
      " [0.80642366 0.5315065  0.25658935 0.03665562]\n",
      " [0.81803119 0.51752994 0.25041771 0.01669451]\n",
      " [0.80373519 0.55070744 0.22325977 0.02976797]\n",
      " [0.786991   0.55745196 0.26233033 0.03279129]\n",
      " [0.82307218 0.51442011 0.24006272 0.01714734]\n",
      " [0.8025126  0.55989251 0.20529392 0.01866308]\n",
      " [0.81120865 0.55945424 0.16783627 0.02797271]\n",
      " [0.77381111 0.59732787 0.2036345  0.05430253]\n",
      " [0.79428944 0.57365349 0.19121783 0.05883625]\n",
      " [0.80327412 0.55126656 0.22050662 0.04725142]\n",
      " [0.8068282  0.53788547 0.24063297 0.04246464]\n",
      " [0.77964883 0.58091482 0.22930848 0.0458617 ]\n",
      " [0.8173379  0.51462016 0.25731008 0.03027177]\n",
      " [0.78591858 0.57017622 0.23115252 0.06164067]\n",
      " [0.77577075 0.60712493 0.16864581 0.03372916]\n",
      " [0.80597792 0.52151512 0.26865931 0.07901744]\n",
      " [0.776114   0.54974742 0.30721179 0.03233808]\n",
      " [0.82647451 0.4958847  0.26447184 0.03305898]\n",
      " [0.79778206 0.5424918  0.25529026 0.06382256]\n",
      " [0.80641965 0.54278246 0.23262105 0.03101614]\n",
      " [0.81609427 0.5336001  0.21971769 0.03138824]\n",
      " [0.79524064 0.54144043 0.27072022 0.03384003]\n",
      " [0.80846584 0.52213419 0.26948861 0.03368608]\n",
      " [0.82225028 0.51771314 0.22840286 0.06090743]\n",
      " [0.76578311 0.60379053 0.22089897 0.0147266 ]\n",
      " [0.77867447 0.59462414 0.19820805 0.02831544]\n",
      " [0.81768942 0.51731371 0.25031309 0.03337508]\n",
      " [0.82512295 0.52807869 0.19802951 0.03300492]\n",
      " [0.82699754 0.52627116 0.19547215 0.03007264]\n",
      " [0.78523221 0.5769053  0.22435206 0.01602515]\n",
      " [0.80212413 0.54690282 0.23699122 0.03646019]\n",
      " [0.80779568 0.53853046 0.23758697 0.03167826]\n",
      " [0.80033301 0.56023311 0.20808658 0.04801998]\n",
      " [0.86093857 0.44003527 0.24871559 0.0573959 ]\n",
      " [0.78609038 0.57170209 0.23225397 0.03573138]\n",
      " [0.78889479 0.55222635 0.25244633 0.09466737]\n",
      " [0.76693897 0.57144472 0.28572236 0.06015208]\n",
      " [0.82210585 0.51381615 0.23978087 0.05138162]\n",
      " [0.77729093 0.57915795 0.24385598 0.030482  ]\n",
      " [0.79594782 0.55370283 0.24224499 0.03460643]\n",
      " [0.79837025 0.55735281 0.22595384 0.03012718]\n",
      " [0.81228363 0.5361072  0.22743942 0.03249135]\n",
      " [0.76701103 0.35063361 0.51499312 0.15340221]\n",
      " [0.74549757 0.37274878 0.52417798 0.17472599]\n",
      " [0.75519285 0.33928954 0.53629637 0.16417236]\n",
      " [0.75384916 0.31524601 0.54825394 0.17818253]\n",
      " [0.7581754  0.32659863 0.5365549  0.17496355]\n",
      " [0.72232962 0.35482858 0.57026022 0.16474184]\n",
      " [0.72634846 0.38046824 0.54187901 0.18446945]\n",
      " [0.75916547 0.37183615 0.51127471 0.15493173]\n",
      " [0.76301853 0.33526572 0.53180079 0.15029153]\n",
      " [0.72460233 0.37623583 0.54345175 0.19508524]\n",
      " [0.76923077 0.30769231 0.53846154 0.15384615]\n",
      " [0.73923462 0.37588201 0.52623481 0.187941  ]\n",
      " [0.78892752 0.28927343 0.52595168 0.13148792]\n",
      " [0.73081412 0.34743622 0.56308629 0.16772783]\n",
      " [0.75911707 0.3931142  0.48800383 0.17622361]\n",
      " [0.76945444 0.35601624 0.50531337 0.16078153]\n",
      " [0.70631892 0.37838513 0.5675777  0.18919257]\n",
      " [0.75676497 0.35228714 0.53495455 0.13047672]\n",
      " [0.76444238 0.27125375 0.55483721 0.18494574]\n",
      " [0.76185188 0.34011245 0.53057542 0.14964948]\n",
      " [0.6985796  0.37889063 0.56833595 0.21312598]\n",
      " [0.77011854 0.35349703 0.50499576 0.16412362]\n",
      " [0.74143307 0.29421947 0.57667016 0.17653168]\n",
      " [0.73659895 0.33811099 0.56754345 0.14490471]\n",
      " [0.76741698 0.34773582 0.51560829 0.15588157]\n",
      " [0.76785726 0.34902603 0.51190484 0.16287881]\n",
      " [0.76467269 0.31486523 0.53976896 0.15743261]\n",
      " [0.74088576 0.33173989 0.55289982 0.18798594]\n",
      " [0.73350949 0.35452959 0.55013212 0.18337737]\n",
      " [0.78667474 0.35883409 0.48304589 0.13801311]\n",
      " [0.76521855 0.33391355 0.52869645 0.15304371]\n",
      " [0.77242925 0.33706004 0.51963422 0.14044168]\n",
      " [0.76434981 0.35581802 0.51395936 0.15814134]\n",
      " [0.70779525 0.31850786 0.60162596 0.1887454 ]\n",
      " [0.69333409 0.38518561 0.57777841 0.1925928 ]\n",
      " [0.71524936 0.40530797 0.53643702 0.19073316]\n",
      " [0.75457341 0.34913098 0.52932761 0.16893434]\n",
      " [0.77530021 0.28304611 0.54147951 0.15998258]\n",
      " [0.72992443 0.39103094 0.53440896 0.16944674]\n",
      " [0.74714194 0.33960997 0.54337595 0.17659719]\n",
      " [0.72337118 0.34195729 0.57869695 0.15782644]\n",
      " [0.73260391 0.36029701 0.55245541 0.1681386 ]\n",
      " [0.76262994 0.34186859 0.52595168 0.1577855 ]\n",
      " [0.76986879 0.35413965 0.5081134  0.15397376]\n",
      " [0.73544284 0.35458851 0.55158213 0.1707278 ]\n",
      " [0.73239618 0.38547167 0.53966034 0.15418867]\n",
      " [0.73446047 0.37367287 0.5411814  0.16750853]\n",
      " [0.75728103 0.3542121  0.52521104 0.15878473]\n",
      " [0.78258054 0.38361791 0.4603415  0.16879188]\n",
      " [0.7431482  0.36505526 0.5345452  0.16948994]\n",
      " [0.65387747 0.34250725 0.62274045 0.25947519]\n",
      " [0.69052512 0.32145135 0.60718588 0.22620651]\n",
      " [0.71491405 0.30207636 0.59408351 0.21145345]\n",
      " [0.69276796 0.31889319 0.61579374 0.1979337 ]\n",
      " [0.68619022 0.31670318 0.61229281 0.232249  ]\n",
      " [0.70953708 0.28008043 0.61617694 0.1960563 ]\n",
      " [0.67054118 0.34211284 0.61580312 0.23263673]\n",
      " [0.71366557 0.28351098 0.61590317 0.17597233]\n",
      " [0.71414125 0.26647062 0.61821183 0.19185884]\n",
      " [0.69198788 0.34599394 0.58626751 0.24027357]\n",
      " [0.71562645 0.3523084  0.56149152 0.22019275]\n",
      " [0.71576546 0.30196356 0.59274328 0.21249287]\n",
      " [0.71718148 0.31640359 0.58007326 0.22148252]\n",
      " [0.6925518  0.30375079 0.60750157 0.24300063]\n",
      " [0.67767924 0.32715549 0.59589036 0.28041899]\n",
      " [0.69589887 0.34794944 0.57629125 0.25008866]\n",
      " [0.70610474 0.3258945  0.59747324 0.1955367 ]\n",
      " [0.69299099 0.34199555 0.60299216 0.19799743]\n",
      " [0.70600618 0.2383917  0.63265489 0.21088496]\n",
      " [0.72712585 0.26661281 0.60593821 0.18178146]\n",
      " [0.70558934 0.32722984 0.58287815 0.23519645]\n",
      " [0.68307923 0.34153961 0.59769433 0.24395687]\n",
      " [0.71486543 0.25995106 0.62202576 0.18567933]\n",
      " [0.73122464 0.31338199 0.56873028 0.20892133]\n",
      " [0.69595601 0.3427843  0.59208198 0.21813547]\n",
      " [0.71529453 0.31790868 0.59607878 0.17882363]\n",
      " [0.72785195 0.32870733 0.56349829 0.21131186]\n",
      " [0.71171214 0.35002236 0.57170319 0.21001342]\n",
      " [0.69594002 0.30447376 0.60894751 0.22835532]\n",
      " [0.73089855 0.30454106 0.58877939 0.1624219 ]\n",
      " [0.72766159 0.27533141 0.59982915 0.18683203]\n",
      " [0.71578999 0.34430405 0.5798805  0.18121266]\n",
      " [0.69417747 0.30370264 0.60740528 0.2386235 ]\n",
      " [0.72366005 0.32162669 0.58582004 0.17230001]\n",
      " [0.69385414 0.29574111 0.63698085 0.15924521]\n",
      " [0.73154399 0.28501714 0.57953485 0.21851314]\n",
      " [0.67017484 0.36168166 0.59571097 0.2553047 ]\n",
      " [0.69804799 0.338117   0.59988499 0.196326  ]\n",
      " [0.71066905 0.35533453 0.56853524 0.21320072]\n",
      " [0.72415258 0.32534391 0.56672811 0.22039426]\n",
      " [0.69997037 0.32386689 0.58504986 0.25073566]\n",
      " [0.73337886 0.32948905 0.54206264 0.24445962]\n",
      " [0.69052512 0.32145135 0.60718588 0.22620651]\n",
      " [0.69193502 0.32561648 0.60035539 0.23403685]\n",
      " [0.68914871 0.33943145 0.58629069 0.25714504]\n",
      " [0.72155725 0.32308533 0.56001458 0.24769876]\n",
      " [0.72965359 0.28954508 0.57909015 0.22005426]\n",
      " [0.71653899 0.3307103  0.57323119 0.22047353]\n",
      " [0.67467072 0.36998072 0.58761643 0.25028107]\n",
      " [0.69025916 0.35097923 0.5966647  0.21058754]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leiil\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but Normalizer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(norm='l2')\n",
    "features_normal2 = normalizer.fit_transform(features)\n",
    "\n",
    "print(features_normal2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a158b7",
   "metadata": {},
   "source": [
    "#### Questão 4: Realize a regularização das features do Iris Dataset utilizando a norma Manhattan (L1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.34313725 0.1372549  0.01960784]\n",
      " [0.51578947 0.31578947 0.14736842 0.02105263]\n",
      " [0.5        0.34042553 0.13829787 0.0212766 ]\n",
      " [0.4893617  0.32978723 0.15957447 0.0212766 ]\n",
      " [0.49019608 0.35294118 0.1372549  0.01960784]\n",
      " [0.47368421 0.34210526 0.14912281 0.03508772]\n",
      " [0.4742268  0.35051546 0.1443299  0.03092784]\n",
      " [0.4950495  0.33663366 0.14851485 0.01980198]\n",
      " [0.49438202 0.3258427  0.15730337 0.02247191]\n",
      " [0.51041667 0.32291667 0.15625    0.01041667]\n",
      " [0.5        0.34259259 0.13888889 0.01851852]\n",
      " [0.48       0.34       0.16       0.02      ]\n",
      " [0.51612903 0.32258065 0.15053763 0.01075269]\n",
      " [0.50588235 0.35294118 0.12941176 0.01176471]\n",
      " [0.51785714 0.35714286 0.10714286 0.01785714]\n",
      " [0.475      0.36666667 0.125      0.03333333]\n",
      " [0.49090909 0.35454545 0.11818182 0.03636364]\n",
      " [0.49514563 0.33980583 0.13592233 0.02912621]\n",
      " [0.49565217 0.33043478 0.14782609 0.02608696]\n",
      " [0.47663551 0.35514019 0.14018692 0.02803738]\n",
      " [0.5046729  0.31775701 0.1588785  0.01869159]\n",
      " [0.47663551 0.34579439 0.14018692 0.03738318]\n",
      " [0.4893617  0.38297872 0.10638298 0.0212766 ]\n",
      " [0.48113208 0.31132075 0.16037736 0.04716981]\n",
      " [0.46601942 0.33009709 0.18446602 0.01941748]\n",
      " [0.51020408 0.30612245 0.16326531 0.02040816]\n",
      " [0.48076923 0.32692308 0.15384615 0.03846154]\n",
      " [0.5        0.33653846 0.14423077 0.01923077]\n",
      " [0.50980392 0.33333333 0.1372549  0.01960784]\n",
      " [0.48453608 0.32989691 0.16494845 0.02061856]\n",
      " [0.49484536 0.31958763 0.16494845 0.02061856]\n",
      " [0.5046729  0.31775701 0.14018692 0.03738318]\n",
      " [0.47706422 0.37614679 0.13761468 0.00917431]\n",
      " [0.48672566 0.37168142 0.12389381 0.01769912]\n",
      " [0.50515464 0.31958763 0.15463918 0.02061856]\n",
      " [0.52083333 0.33333333 0.125      0.02083333]\n",
      " [0.52380952 0.33333333 0.12380952 0.01904762]\n",
      " [0.49       0.36       0.14       0.01      ]\n",
      " [0.49438202 0.33707865 0.14606742 0.02247191]\n",
      " [0.5        0.33333333 0.14705882 0.01960784]\n",
      " [0.4950495  0.34653465 0.12871287 0.02970297]\n",
      " [0.53571429 0.27380952 0.1547619  0.03571429]\n",
      " [0.48351648 0.35164835 0.14285714 0.02197802]\n",
      " [0.46728972 0.3271028  0.14953271 0.05607477]\n",
      " [0.45535714 0.33928571 0.16964286 0.03571429]\n",
      " [0.50526316 0.31578947 0.14736842 0.03157895]\n",
      " [0.47663551 0.35514019 0.14953271 0.01869159]\n",
      " [0.4893617  0.34042553 0.14893617 0.0212766 ]\n",
      " [0.4953271  0.34579439 0.14018692 0.01869159]\n",
      " [0.50505051 0.33333333 0.14141414 0.02020202]\n",
      " [0.42944785 0.19631902 0.28834356 0.08588957]\n",
      " [0.41025641 0.20512821 0.28846154 0.09615385]\n",
      " [0.42073171 0.18902439 0.29878049 0.09146341]\n",
      " [0.41984733 0.17557252 0.30534351 0.09923664]\n",
      " [0.42207792 0.18181818 0.2987013  0.0974026 ]\n",
      " [0.3986014  0.1958042  0.31468531 0.09090909]\n",
      " [0.39622642 0.20754717 0.29559748 0.10062893]\n",
      " [0.42241379 0.20689655 0.28448276 0.0862069 ]\n",
      " [0.42857143 0.18831169 0.2987013  0.08441558]\n",
      " [0.39393939 0.20454545 0.29545455 0.10606061]\n",
      " [0.43478261 0.17391304 0.30434783 0.08695652]\n",
      " [0.40410959 0.20547945 0.28767123 0.10273973]\n",
      " [0.45454545 0.16666667 0.3030303  0.07575758]\n",
      " [0.40397351 0.19205298 0.31125828 0.09271523]\n",
      " [0.41791045 0.21641791 0.26865672 0.09701493]\n",
      " [0.42948718 0.19871795 0.28205128 0.08974359]\n",
      " [0.38356164 0.20547945 0.30821918 0.10273973]\n",
      " [0.42647059 0.19852941 0.30147059 0.07352941]\n",
      " [0.43055556 0.15277778 0.3125     0.10416667]\n",
      " [0.42748092 0.19083969 0.29770992 0.08396947]\n",
      " [0.37579618 0.20382166 0.30573248 0.11464968]\n",
      " [0.42957746 0.1971831  0.28169014 0.0915493 ]\n",
      " [0.41447368 0.16447368 0.32236842 0.09868421]\n",
      " [0.41216216 0.18918919 0.31756757 0.08108108]\n",
      " [0.4295302  0.19463087 0.2885906  0.08724832]\n",
      " [0.42857143 0.19480519 0.28571429 0.09090909]\n",
      " [0.43037975 0.17721519 0.30379747 0.08860759]\n",
      " [0.40853659 0.18292683 0.30487805 0.10365854]\n",
      " [0.40268456 0.19463087 0.30201342 0.10067114]\n",
      " [0.4453125  0.203125   0.2734375  0.078125  ]\n",
      " [0.4296875  0.1875     0.296875   0.0859375 ]\n",
      " [0.43650794 0.19047619 0.29365079 0.07936508]\n",
      " [0.42647059 0.19852941 0.28676471 0.08823529]\n",
      " [0.38961039 0.17532468 0.33116883 0.1038961 ]\n",
      " [0.375      0.20833333 0.3125     0.10416667]\n",
      " [0.38709677 0.21935484 0.29032258 0.10322581]\n",
      " [0.41875    0.19375    0.29375    0.09375   ]\n",
      " [0.44055944 0.16083916 0.30769231 0.09090909]\n",
      " [0.4        0.21428571 0.29285714 0.09285714]\n",
      " [0.41353383 0.18796992 0.30075188 0.09774436]\n",
      " [0.40145985 0.18978102 0.32116788 0.08759124]\n",
      " [0.40397351 0.1986755  0.30463576 0.09271523]\n",
      " [0.42647059 0.19117647 0.29411765 0.08823529]\n",
      " [0.43103448 0.19827586 0.28448276 0.0862069 ]\n",
      " [0.4057971  0.19565217 0.30434783 0.0942029 ]\n",
      " [0.40425532 0.21276596 0.29787234 0.08510638]\n",
      " [0.40425532 0.20567376 0.29787234 0.09219858]\n",
      " [0.42176871 0.19727891 0.29251701 0.08843537]\n",
      " [0.43589744 0.21367521 0.25641026 0.09401709]\n",
      " [0.41007194 0.20143885 0.29496403 0.09352518]\n",
      " [0.3480663  0.18232044 0.33149171 0.13812155]\n",
      " [0.37419355 0.17419355 0.32903226 0.12258065]\n",
      " [0.39226519 0.16574586 0.32596685 0.1160221 ]\n",
      " [0.37951807 0.1746988  0.3373494  0.10843373]\n",
      " [0.37142857 0.17142857 0.33142857 0.12571429]\n",
      " [0.39378238 0.15544041 0.34196891 0.10880829]\n",
      " [0.36029412 0.18382353 0.33088235 0.125     ]\n",
      " [0.3989071  0.15846995 0.3442623  0.09836066]\n",
      " [0.39880952 0.14880952 0.3452381  0.10714286]\n",
      " [0.37113402 0.18556701 0.31443299 0.12886598]\n",
      " [0.38690476 0.19047619 0.30357143 0.11904762]\n",
      " [0.39263804 0.16564417 0.32515337 0.11656442]\n",
      " [0.3908046  0.17241379 0.31609195 0.12068966]\n",
      " [0.375      0.16447368 0.32894737 0.13157895]\n",
      " [0.36024845 0.17391304 0.31677019 0.14906832]\n",
      " [0.37209302 0.18604651 0.30813953 0.13372093]\n",
      " [0.38690476 0.17857143 0.32738095 0.10714286]\n",
      " [0.37745098 0.18627451 0.32843137 0.10784314]\n",
      " [0.39487179 0.13333333 0.35384615 0.11794872]\n",
      " [0.40816327 0.14965986 0.34013605 0.10204082]\n",
      " [0.38121547 0.17679558 0.31491713 0.12707182]\n",
      " [0.36601307 0.18300654 0.32026144 0.13071895]\n",
      " [0.40104167 0.14583333 0.34895833 0.10416667]\n",
      " [0.40127389 0.17197452 0.31210191 0.11464968]\n",
      " [0.37640449 0.18539326 0.32022472 0.11797753]\n",
      " [0.3956044  0.17582418 0.32967033 0.0989011 ]\n",
      " [0.3974359  0.17948718 0.30769231 0.11538462]\n",
      " [0.38607595 0.18987342 0.31012658 0.11392405]\n",
      " [0.37869822 0.16568047 0.33136095 0.12426036]\n",
      " [0.40909091 0.17045455 0.32954545 0.09090909]\n",
      " [0.40659341 0.15384615 0.33516484 0.1043956 ]\n",
      " [0.39303483 0.18905473 0.31840796 0.09950249]\n",
      " [0.37647059 0.16470588 0.32941176 0.12941176]\n",
      " [0.40127389 0.17834395 0.32484076 0.0955414 ]\n",
      " [0.38853503 0.1656051  0.3566879  0.08917197]\n",
      " [0.40314136 0.15706806 0.31937173 0.12041885]\n",
      " [0.3559322  0.1920904  0.31638418 0.13559322]\n",
      " [0.38095238 0.18452381 0.32738095 0.10714286]\n",
      " [0.38461538 0.19230769 0.30769231 0.11538462]\n",
      " [0.39428571 0.17714286 0.30857143 0.12      ]\n",
      " [0.37640449 0.1741573  0.31460674 0.13483146]\n",
      " [0.39655172 0.17816092 0.29310345 0.13218391]\n",
      " [0.37419355 0.17419355 0.32903226 0.12258065]\n",
      " [0.37362637 0.17582418 0.32417582 0.12637363]\n",
      " [0.36813187 0.18131868 0.31318681 0.13736264]\n",
      " [0.38953488 0.1744186  0.30232558 0.13372093]\n",
      " [0.40127389 0.15923567 0.31847134 0.12101911]\n",
      " [0.38922156 0.17964072 0.31137725 0.11976048]\n",
      " [0.3583815  0.19653179 0.31213873 0.13294798]\n",
      " [0.37341772 0.18987342 0.32278481 0.11392405]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leiil\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but Normalizer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(norm='l1')\n",
    "features_normal1 = normalizer.fit_transform(features)\n",
    "\n",
    "print(features_normal1)\n",
    "print(np.sum(features_normal1, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da297e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_dict = load_breast_cancer()\n",
    "data = breast_cancer_dict['data']\n",
    "feature_names = breast_cancer_dict['feature_names']\n",
    "target = breast_cancer_dict['target']\n",
    "\n",
    "breast_cancer_df = pd.DataFrame(data, columns=feature_names)\n",
    "breast_cancer_df['target'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db14d9",
   "metadata": {},
   "source": [
    "## Parte 2 Seleção de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a639d7",
   "metadata": {},
   "source": [
    "#### Questão 5: Considere o Breast Cancer Dataset. Proponha uma estratégia de filtragem para selecionar um conjunto de features mais significativas e justifique sua resposta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc8db207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features após Variance Threshold:\n",
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'perimeter error', 'area error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area']\n"
     ]
    }
   ],
   "source": [
    "features = breast_cancer_df.drop(columns='target')\n",
    "target = breast_cancer_df['target']\n",
    "\n",
    "threshold = VarianceThreshold(threshold=0.5)\n",
    "features_high_variance = threshold.fit_transform(features)\n",
    "high_variance_features = features.columns[threshold.get_support()]\n",
    "\n",
    "print(\"Features após Variance Threshold:\")\n",
    "print(high_variance_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9a0a75",
   "metadata": {},
   "source": [
    "#### Questão 6: Repita a Questão 5, mas agora utilizando o método Wrapper para selecionar as features. Compare os resultados obtidos com os da abordagem de filtragem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce32a37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número adequado de features: 20\n",
      "Features selecionadas com RFECV: ['mean radius', 'mean texture', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'texture error', 'perimeter error', 'area error', 'compactness error', 'worst radius', 'worst texture', 'worst perimeter', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(action = \"ignore\", module = \"scipy\", message = \"^internal gelsd\")\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(features, target)\n",
    "\n",
    "selected_features = features.columns[rfecv.support_]\n",
    "print(\"Número adequado de features:\", rfecv.n_features_)\n",
    "print(\"Features selecionadas com RFECV:\", selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848684a5",
   "metadata": {},
   "source": [
    "#### Questão 7:Descreva o funcionamento do método de seleção de features conhecido como Embedding. Explique por que ele é computacionalmente mais barato que o Wrapper, justificando sua resposta;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b7989",
   "metadata": {},
   "source": [
    "*O método de seleção de features Embedding realiza a seleção de atributos durante o processo de treinamento do modelo, o algoritmo aprende a importância de cada feature, atribuindo pesos conforme sua relevância, e as features menos relevantes podem ser descartadas automaticamente ao longo do treinamento ou após sua conclusão. Esse método é computacionalmente mais barato do que o Wrapper porque não exige múltiplos treinamentos do modelo. No modelo wrapper o treinamento acontece várias vezes para cada combinação de features testado, o que gera um alto custo computacional, já o Embedding realiza apenas um treinamento o que o torna mais eficiente em termos de tempo e uso de recursos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a38fb",
   "metadata": {},
   "source": [
    "### Parte 3 Processamento de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7117027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"A alma é, pois, imortal; renasceu repetidas vezes na existência e contemplou todas as coisas existentes e por isso não há nada que ela não conheça! Não é de espantar que ela seja capaz de evocar à memória a lembrança de objetos que viu anteriormente, e que se relacionam tanto com a virtude como com as outras coisas existentes. Toda a natureza, com efeito, é uma só, é um todo orgânico, e o espírito já viu todas as coisas; logo, nada impede que ao nos lembrarmos de uma coisa – o que nós, homens, chamamos de “saber” – todas as outras coisas acorram imediata e maquinalmente à nossa consciência.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee13d7",
   "metadata": {},
   "source": [
    "#### Questão 8: Utilize o método Bag-of-Words para transformar o texto acima em um vetor. Apresente a vetorização obtida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40fe6c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário: 63\n",
      "Conteúdo de vocabulário\n",
      " {'alma': 1, 'pois': 44, 'imortal': 25, 'renasceu': 48, 'repetidas': 49, 'vezes': 60, 'na': 34, 'existência': 21, 'contemplou': 13, 'todas': 56, 'as': 4, 'coisas': 8, 'existentes': 20, 'por': 45, 'isso': 27, 'não': 39, 'há': 23, 'nada': 35, 'que': 46, 'ela': 16, 'conheça': 11, 'de': 14, 'espantar': 17, 'seja': 52, 'capaz': 5, 'evocar': 19, 'memória': 33, 'lembrança': 29, 'objetos': 41, 'viu': 62, 'anteriormente': 2, 'se': 51, 'relacionam': 47, 'tanto': 54, 'com': 9, 'virtude': 61, 'como': 10, 'outras': 43, 'toda': 55, 'natureza': 36, 'efeito': 15, 'uma': 59, 'só': 53, 'um': 58, 'todo': 57, 'orgânico': 42, 'espírito': 18, 'já': 28, 'logo': 31, 'impede': 26, 'ao': 3, 'nos': 37, 'lembrarmos': 30, 'coisa': 7, 'nós': 40, 'homens': 22, 'chamamos': 6, 'saber': 50, 'acorram': 0, 'imediata': 24, 'maquinalmente': 32, 'nossa': 38, 'consciência': 12}\n"
     ]
    }
   ],
   "source": [
    "texto_limpo = []\n",
    "texto_limpo.append(texto.translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(texto_limpo)\n",
    "\n",
    "print(f\"Tamanho do vocabulário: {len(vect.vocabulary_)}\")\n",
    "print(f\"Conteúdo de vocabulário\\n {vect.vocabulary_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb3ded4",
   "metadata": {},
   "source": [
    "### Questão 9:Utilize o método Bag-of-n-Grams para vetorizar o texto e apresente:\n",
    " * O número de unigrams.\n",
    " * O número de bigrams.\n",
    " * O número de trigrams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7fbfbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de unigrams\n",
      "Tamanho do vocabulário: 63\n",
      "Conteúdo de vocabulário:\n",
      "['acorram' 'alma' 'anteriormente' 'ao' 'as' 'capaz' 'chamamos' 'coisa'\n",
      " 'coisas' 'com' 'como' 'conheça' 'consciência' 'contemplou' 'de' 'efeito'\n",
      " 'ela' 'espantar' 'espírito' 'evocar' 'existentes' 'existência' 'homens'\n",
      " 'há' 'imediata' 'imortal' 'impede' 'isso' 'já' 'lembrança' 'lembrarmos'\n",
      " 'logo' 'maquinalmente' 'memória' 'na' 'nada' 'natureza' 'nos' 'nossa'\n",
      " 'não' 'nós' 'objetos' 'orgânico' 'outras' 'pois' 'por' 'que' 'relacionam'\n",
      " 'renasceu' 'repetidas' 'saber' 'se' 'seja' 'só' 'tanto' 'toda' 'todas'\n",
      " 'todo' 'um' 'uma' 'vezes' 'virtude' 'viu']\n",
      "\n",
      "O número de bigrams\n",
      "Tamanho do vocabulário: 82\n",
      "Conteúdo de vocabulário:\n",
      "['acorram imediata' 'alma pois' 'anteriormente que' 'ao nos' 'as coisas'\n",
      " 'as outras' 'capaz de' 'chamamos de' 'coisa que' 'coisas acorram'\n",
      " 'coisas existentes' 'coisas logo' 'com as' 'com efeito' 'com virtude'\n",
      " 'como com' 'conheça não' 'contemplou todas' 'de espantar' 'de evocar'\n",
      " 'de objetos' 'de saber' 'de uma' 'efeito uma' 'ela não' 'ela seja'\n",
      " 'espantar que' 'espírito já' 'evocar memória' 'existentes por'\n",
      " 'existentes toda' 'existência contemplou' 'homens chamamos' 'há nada'\n",
      " 'imediata maquinalmente' 'imortal renasceu' 'impede que' 'isso não'\n",
      " 'já viu' 'lembrança de' 'lembrarmos de' 'logo nada' 'maquinalmente nossa'\n",
      " 'memória lembrança' 'na existência' 'nada impede' 'nada que'\n",
      " 'natureza com' 'nos lembrarmos' 'nossa consciência' 'não conheça'\n",
      " 'não de' 'não há' 'nós homens' 'objetos que' 'orgânico espírito'\n",
      " 'outras coisas' 'pois imortal' 'por isso' 'que ao' 'que ela' 'que nós'\n",
      " 'que se' 'que viu' 'relacionam tanto' 'renasceu repetidas'\n",
      " 'repetidas vezes' 'saber todas' 'se relacionam' 'seja capaz' 'só um'\n",
      " 'tanto com' 'toda natureza' 'todas as' 'todo orgânico' 'um todo'\n",
      " 'uma coisa' 'uma só' 'vezes na' 'virtude como' 'viu anteriormente'\n",
      " 'viu todas']\n",
      "\n",
      "O número de trigrams\n",
      "Tamanho do vocabulário: 86\n",
      "Conteúdo de vocabulário:\n",
      "['acorram imediata maquinalmente' 'alma pois imortal'\n",
      " 'anteriormente que se' 'ao nos lembrarmos' 'as coisas existentes'\n",
      " 'as coisas logo' 'as outras coisas' 'capaz de evocar' 'chamamos de saber'\n",
      " 'coisa que nós' 'coisas acorram imediata' 'coisas existentes por'\n",
      " 'coisas existentes toda' 'coisas logo nada' 'com as outras'\n",
      " 'com efeito uma' 'com virtude como' 'como com as' 'conheça não de'\n",
      " 'contemplou todas as' 'de espantar que' 'de evocar memória'\n",
      " 'de objetos que' 'de saber todas' 'de uma coisa' 'efeito uma só'\n",
      " 'ela não conheça' 'ela seja capaz' 'espantar que ela' 'espírito já viu'\n",
      " 'evocar memória lembrança' 'existentes por isso'\n",
      " 'existentes toda natureza' 'existência contemplou todas'\n",
      " 'homens chamamos de' 'há nada que' 'imediata maquinalmente nossa'\n",
      " 'imortal renasceu repetidas' 'impede que ao' 'isso não há' 'já viu todas'\n",
      " 'lembrança de objetos' 'lembrarmos de uma' 'logo nada impede'\n",
      " 'maquinalmente nossa consciência' 'memória lembrança de'\n",
      " 'na existência contemplou' 'nada impede que' 'nada que ela'\n",
      " 'natureza com efeito' 'nos lembrarmos de' 'não conheça não'\n",
      " 'não de espantar' 'não há nada' 'nós homens chamamos' 'objetos que viu'\n",
      " 'orgânico espírito já' 'outras coisas acorram' 'outras coisas existentes'\n",
      " 'pois imortal renasceu' 'por isso não' 'que ao nos' 'que ela não'\n",
      " 'que ela seja' 'que nós homens' 'que se relacionam'\n",
      " 'que viu anteriormente' 'relacionam tanto com' 'renasceu repetidas vezes'\n",
      " 'repetidas vezes na' 'saber todas as' 'se relacionam tanto'\n",
      " 'seja capaz de' 'só um todo' 'tanto com virtude' 'toda natureza com'\n",
      " 'todas as coisas' 'todas as outras' 'todo orgânico espírito'\n",
      " 'um todo orgânico' 'uma coisa que' 'uma só um' 'vezes na existência'\n",
      " 'virtude como com' 'viu anteriormente que' 'viu todas as']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unigrams = CountVectorizer(ngram_range=(1, 1)).fit(texto_limpo)\n",
    "print(\"O número de unigrams\")\n",
    "print(f\"Tamanho do vocabulário: {len(unigrams.vocabulary_)}\")\n",
    "print(f\"Conteúdo de vocabulário:\\n{unigrams.get_feature_names_out()}\")\n",
    "\n",
    "\n",
    "bigrams = CountVectorizer(ngram_range=(2, 2)).fit(texto_limpo)\n",
    "print(\"\\nO número de bigrams\")\n",
    "print(f\"Tamanho do vocabulário: {len(bigrams.vocabulary_)}\")\n",
    "print(f\"Conteúdo de vocabulário:\\n{bigrams.get_feature_names_out()}\")\n",
    "\n",
    "\n",
    "trigrams = CountVectorizer(ngram_range=(3, 3)).fit(texto_limpo)\n",
    "print(\"\\nO número de trigrams\")\n",
    "print(f\"Tamanho do vocabulário: {len(trigrams.vocabulary_)}\")\n",
    "print(f\"Conteúdo de vocabulário:\\n{trigrams.get_feature_names_out()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5683c",
   "metadata": {},
   "source": [
    "#### Questão 10: Utilizando o pacote NLTK, remova as stopwords do texto e apresente o resultado obtido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3b271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto sem stopwords: ['alma', 'é,', 'pois,', 'imortal;', 'renasceu', 'repetidas', 'vezes', 'existência', 'contemplou', 'todas', 'coisas', 'existentes', 'nada', 'conheça!', 'espantar', 'capaz', 'evocar', 'memória', 'lembrança', 'objetos', 'viu', 'anteriormente,', 'relacionam', 'tanto', 'virtude', 'outras', 'coisas', 'existentes.', 'toda', 'natureza,', 'efeito,', 'só,', 'todo', 'orgânico,', 'espírito', 'viu', 'todas', 'coisas;', 'logo,', 'nada', 'impede', 'lembrarmos', 'coisa', '–', 'nós,', 'homens,', 'chamamos', '“saber”', '–', 'todas', 'outras', 'coisas', 'acorram', 'imediata', 'maquinalmente', 'consciência.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Leiil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords_pt = set(stopwords.words('portuguese'))\n",
    "\n",
    "palavras = texto.lower().split()\n",
    "palavras_filtradas = [p for p in palavras if p not in stopwords_pt]\n",
    "\n",
    "print(\"Texto sem stopwords:\", palavras_filtradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f5788",
   "metadata": {},
   "source": [
    "#### Questão 11: Utilize o NLTK para aplicar stemming no texto. Apresente o resultado obtido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0121af3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming: ['alm', 'é,', 'pois,', 'imortal;', 'renasc', 'repet', 'vez', 'exist', 'contempl', 'tod', 'cois', 'exist', 'nad', 'conheça!', 'espant', 'capaz', 'evoc', 'memór', 'lembranç', 'objet', 'viu', 'anteriormente,', 'relacion', 'tant', 'virtud', 'outr', 'cois', 'existentes.', 'tod', 'natureza,', 'efeito,', 'só,', 'tod', 'orgânico,', 'espírit', 'viu', 'tod', 'coisas;', 'logo,', 'nad', 'imped', 'lembr', 'cois', '–', 'nós,', 'homens,', 'cham', '“saber”', '–', 'tod', 'outr', 'cois', 'acorr', 'imediat', 'maqu', 'consciência.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\Leiil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('rslp')\n",
    "stemmer = RSLPStemmer()\n",
    "stems = [stemmer.stem(p) for p in palavras_filtradas]\n",
    "\n",
    "print(\"Stemming:\", stems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c1d10",
   "metadata": {},
   "source": [
    "#### Questão 12: Utilize o NLTK para aplicar lemmatization no texto. Apresente o resultado obtido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae9dde81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization: ['alma', 'imortal', 'renascer', 'repetido', 'existência', 'contemplar', 'coisa', 'existente', 'haver', 'conhecer', 'espantar', 'ser', 'capaz', 'evocar', 'memória', 'lembrança', 'objeto', 'ver', 'anteriormente', 'relacionar', 'virtude', 'coisa', 'existente', 'natureza', 'efeito', 'orgânico', 'espírito', 'ver', 'coisa', 'impedir', 'lembrarmo', 'homem', 'chamar', 'coisa', 'acorr', 'imediato', 'maquinalmente', 'consciência']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "doc = nlp(texto)\n",
    "palavras_lematizadas = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "print(\"Lemmatization:\", palavras_lematizadas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
